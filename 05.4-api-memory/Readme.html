<h1 id="lab-6.1-memory-management-in-spark">Lab 6.1 Memory Management in spark</h1>
<h3 id="overview">Overview</h3>
<p>Managing and avoiding out of memory error in spark Here we will be loading sample datasets of statistical computing and will be understanding the following,</p>
<ol type="1">
<li>How out of memory error occurs in spark executor</li>
<li>How to resolve that error</li>
</ol>
<h3 id="depends-on">Depends On</h3>
<p>Should contain more than one node in the cluster for wide shuffle to happen</p>
<h3 id="run-time">Run time</h3>
<p>20-30 mins</p>
<h2 id="step-1-edit-source-file">STEP 1: Edit source file</h2>
<p>Go to the project root directory</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb1-1" data-line-number="1">    $    <span class="bu">cd</span> ~/spark-labs/07-api-java/advanced.spark</a></code></pre></div>
<p><strong>=&gt; Edit file : <code>~/spark-labs/advanced.spark/src/main/java/advance/spark/MemoryManagement.java</code></strong><br />
<strong>=&gt; And fix the TODO items</strong></p>
<h2 id="step-2-compile-the-project">STEP 2: Compile the project</h2>
<p>We will use <code>maven</code> to build the project.</p>
<p><strong>=&gt; Inspect the <code>pom.xml</code> file</strong></p>
<p>The file will look follows:</p>
<pre><code>&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
  &lt;groupId&gt;com.elephantscale&lt;/groupId&gt;
  &lt;artifactId&gt;spark.basic&lt;/artifactId&gt;
  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
  &lt;dependencies&gt;
        &lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
            &lt;artifactId&gt;spark-core_2.11&lt;/artifactId&gt;
            &lt;version&gt;2.3.2&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
            &lt;artifactId&gt;spark-sql_2.11&lt;/artifactId&gt;
            &lt;version&gt;2.3.2&lt;/version&gt;
        &lt;/dependency&gt;

    &lt;/dependencies&gt;
    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;
                &lt;version&gt;2.4.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;!-- get all project dependencies --&gt;
                    &lt;descriptorRefs&gt;
                        &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;
                    &lt;/descriptorRefs&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;id&gt;make-assembly&lt;/id&gt;
                        &lt;!-- bind to the packaging phase --&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;single&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;</code></pre>
<p><strong>=&gt; Kick off a build</strong><br />
(This will take a few minutes for the first time you run it)</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb3-1" data-line-number="1">    <span class="co"># be in the project root level directory</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2">    $   <span class="bu">cd</span>   ~/spark-labs/07-api-java/advanced.spark</a>
<a class="sourceLine" id="cb3-3" data-line-number="3"></a>
<a class="sourceLine" id="cb3-4" data-line-number="4">    $   <span class="ex">mvn</span> package</a>
<a class="sourceLine" id="cb3-5" data-line-number="5"></a>
<a class="sourceLine" id="cb3-6" data-line-number="6">    <span class="co"># to do a clean rebuild use</span></a>
<a class="sourceLine" id="cb3-7" data-line-number="7">    $  <span class="ex">mvn</span> clean package</a></code></pre></div>
<p>Make sure there are no errors and there is output in <code>target</code> dir.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb4-1" data-line-number="1">    $  <span class="fu">ls</span> -l   target/</a></code></pre></div>
<p>You should see output like follows</p>
<pre class="console"><code>drwxrwxr-x 2 sujee staff      4096 Jan 23 19:08 archive-tmp
drwxrwxr-x 3 sujee staff      4096 Jan 23 19:09 classes
drwxrwxr-x 2 sujee staff      4096 Jan 23 19:08 maven-archiver
drwxrwxr-x 3 sujee staff      4096 Jan 23 19:08 maven-status
-rw-rw-r-- 1 sujee staff      5273 Jan 23 19:08 spark.basic-0.0.1-SNAPSHOT.jar
-rw-rw-r-- 1 sujee staff 128676623 Jan 23 19:08 spark.basic-0.0.1-SNAPSHOT-jar-with-dependencies.jar
drwxrwxr-x 2 sujee staff      4096 Jan 23 19:08 test-classes</code></pre>
<p><code>spark.basic-0.0.1-SNAPSHOT-jar-with-dependencies.jar</code> is our code compiled.</p>
<h2 id="step-3-test-application-in-local-master-mode">STEP 3: Test Application in Local Master Mode</h2>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb6-1" data-line-number="1">    $  <span class="bu">cd</span>  ~/spark-labs/07-api-java/advanced.spark</a>
<a class="sourceLine" id="cb6-2" data-line-number="2"></a>
<a class="sourceLine" id="cb6-3" data-line-number="3">    $   <span class="ex">~/spark/bin/spark-submit</span> --class <span class="st">&#39;spark.basic.MemoryManagement&#39;</span> target/spark.basic-0.0.1-SNAPSHOT-jar-with-dependencies.jar</a></code></pre></div>
<p><strong>==&gt; Checkout the Shell UI (4040)</strong></p>
<p><strong>==&gt; Hit Enter key to terminate the program</strong></p>
<p><strong>==&gt; Turn off the logs by sending logs by <code>2&gt; logs</code> </strong></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb7-1" data-line-number="1">    $   <span class="ex">~/spark/bin/spark-submit</span> --class <span class="st">&#39;spark.basic.MemoryManagement&#39;</span> target/spark.basic-0.0.1-SNAPSHOT-jar-with-dependencies.jar  <span class="op">2&gt;</span> logs</a></code></pre></div>
<p>Now letâ€™s submit the application to Spark server</p>
<h2 id="step-4-start-spark-server">STEP 4: Start Spark Server</h2>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb8-1" data-line-number="1">    $  <span class="ex">~/spark/sbin/start-all.sh</span></a></code></pre></div>
<p><strong>=&gt; Check the Spark Server UI at port 8080.</strong><br />
<strong>=&gt; Note the Spark master URL.</strong></p>
<p><img src="../assets/images/4.1b.png" style="border: 5px solid grey; max-width:100%;"/></p>
<h2 id="step-5-submit-the-application">STEP 5: Submit the application</h2>
<p>Use the following command to submit the job</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb9-1" data-line-number="1">    $  <span class="bu">cd</span>  ~/spark-labs/07-api-java</a>
<a class="sourceLine" id="cb9-2" data-line-number="2"></a>
<a class="sourceLine" id="cb9-3" data-line-number="3">    $   <span class="ex">~/spark/bin/spark-submit</span> --class <span class="st">&#39;spark.basic.MemoryManagement&#39;</span> target/spark.basic-0.0.1-SNAPSHOT-jar-with-dependencies.jar <span class="op">2&gt;</span>logs</a></code></pre></div>
<ul>
<li>MASTER URL : substitute your spark master url</li>
<li>for files you can try <code>README.md</code></li>
</ul>
<p><strong>=&gt; Watch the console output</strong></p>
<p>It may look like this</p>
<pre class="console"><code>Started processing...
Number of rows in the fle: 7009729</code></pre>
<p>The lines starting with <code>###</code> are output from our program</p>
<h2 id="step-6-configuring-logging">STEP 6: Configuring logging</h2>
<h4 id="to-quickly-turn-off-the-logging">To quickly turn off the logging:</h4>
<p>Redirect the logs as follows <code>2&gt; logs</code>.<br />
All logs will be sent to <code>logs</code> file.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb11-1" data-line-number="1">    $  <span class="ex">~/spark/bin/spark-submit</span> --class <span class="st">&#39;spark.basic.MemoryManagement&#39;</span>  target/spark.basic-0.0.1-SNAPSHOT-jar-with-dependencies.jar <span class="op">2&gt;</span>  logs</a></code></pre></div>
<h4 id="using-log4j-config">Using log4j config</h4>
<p>Spark by default logs at INFO level. While there is a lot of useful information there, it can be quite verbose.</p>
<p>We have a <code>logging/log4j.properties</code> file. Inspect this file</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb12-1" data-line-number="1">    $    <span class="fu">cat</span>   logging/log4j.properties</a></code></pre></div>
<p>The file has following contents</p>
<pre><code># Set everything to be logged to the console
log4j.rootCategory=WARN, console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# Settings to quiet third party logs that are too verbose
log4j.logger.org.eclipse.jetty=WARN
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO

## set log levels for our loggers
## everything under &#39;x&#39; package
#log4j.logger.x=INFO
## specific file
#log4j.logger.spark.basic.Shuffling=DEBUG</code></pre>
<p>We provide <code>--driver-class-path logging/</code> to spark-submit to turn off logging</p>
<p>Here is an example</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb14-1" data-line-number="1">    $   <span class="ex">~/spark/bin/spark-submit</span> --class <span class="st">&#39;spark.basic.MemoryManagement&#39;</span> --driver-class-path logging/  target/spark.basic-0.0.1-SNAPSHOT-jar-with-dependencies.jar   </a></code></pre></div>
