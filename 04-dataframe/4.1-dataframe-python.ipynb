{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.1 : Spark Dataframes\n",
    "\n",
    "\n",
    "### Overview\n",
    "First look at Spark Dataframes\n",
    "\n",
    "### Depends On \n",
    "None\n",
    "\n",
    "### Run time\n",
    "20-30 mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Spark Session\n",
    "import os\n",
    "import sys\n",
    "top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "if top_dir not in sys.path:\n",
    "    sys.path.append(top_dir)\n",
    "\n",
    "from init_spark import init_spark\n",
    "spark = init_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Load Clickstream data\n",
    "\n",
    "The clickstream data looks like this\n",
    "\n",
    "```json\n",
    "{\"timestamp\": 1420070400000, \"ip\": \"ip_557\", \"user\": \"user_13011\", \"action\": \"blocked\", \"domain\": \"npr.org\", \"campaign\": \"campaign_13\", \"cost\": 116, \"session\": \"session_43\"}\n",
    "\n",
    "{\"timestamp\": 1420070400043, \"ip\": \"ip_129\", \"user\": \"user_58773\", \"action\": \"clicked\", \"domain\": \"flickr.com\", \"campaign\": \"campaign_7\", \"cost\": 170, \"session\": \"session_23\"}\n",
    "\n",
    "{\"timestamp\": 1420070400086, \"ip\": \"ip_704\", \"user\": \"user_71191\", \"action\": \"viewed\", \"domain\": \"foxnews.com\", \"campaign\": \"campaign_20\", \"cost\": 47, \"session\": \"session_48\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "clickstreamDF = spark.read.json(\"../data/click-stream/clickstream.json\")\n",
    "print(clickstreamDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==> Monitor Spark shell UI on port 4040+**  \n",
    "You may see something like this:\n",
    "\n",
    "**==> Q : Why is Spark not lazy loading the JSON files?**\n",
    "\n",
    "<img src=\"../assets/images/5.1a.png\" style=\"border: 5px solid grey; max-width:100%;\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## STEP 2 : Inspecting The Dataframe\n",
    "\n",
    "**==> Print the schema of data frame**     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickstreamDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==> Print / Dump the data contained within dataframe**  \n",
    "Your output may look like this:\n",
    "\n",
    "```\n",
    "+-------+-----------+----+-----------------+----+----------+-------------+------+\n",
    "| action|   campaign|cost|           domain|  ip|   session|    timestamp|  user|\n",
    "+-------+-----------+----+-----------------+----+----------+-------------+------+\n",
    "|clicked|campaign_19| 118|      youtube.com|ip_4|session_36|1420070400000|user_9|\n",
    "|blocked|campaign_12|   5|     facebook.com|ip_3|session_96|1420070400864|user_5|\n",
    "|clicked| campaign_3|  54|sf.craigslist.org|ip_9|session_61|1420070401728|user_8|\n",
    "...\n",
    "\n",
    "```\n",
    "\n",
    "**==> Let's see the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickstreamDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==> Explore methods available in Dataframe**  \n",
    "Here is the Dataframe API : \n",
    "[Scala](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame)  /\n",
    "[Java](http://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/DataFrame.html) / \n",
    "[Python](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html?highlight=dataframe#pyspark.sql.DataFrame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## STEP 3 : Querying Dataframe\n",
    "\n",
    "**==> Show only click logs where the cost > 100**\n",
    "\n",
    "Sample output\n",
    "\n",
    "```\n",
    "    +-------+-----------+----+-----------------+----+----------+-------------+------+\n",
    "    | action|   campaign|cost|           domain|  ip|   session|    timestamp|  user|\n",
    "    +-------+-----------+----+-----------------+----+----------+-------------+------+\n",
    "    |clicked|campaign_19| 118|      youtube.com|ip_4|session_36|1420070400000|user_9|\n",
    "    |blocked|campaign_18| 110|    wikipedia.org|ip_5|session_55|1420070402592|user_6|\n",
    "    |blocked| campaign_9| 139|          cnn.com|ip_8|session_13|1420070404320|user_7|\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickstreamDF.filter(\"cost > ???\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same thing\n",
    "clickstreamDF.filter(clickstreamDF['cost'] > ???).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==> Show the logs where action = clicked**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: show the logs where action = clicked\n",
    "# Hint : clickstreamDF.filter(\"action == '???'\")\n",
    "clickstreamDF.filter (\"??? == '???'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO Another approach\n",
    "clickstreamDF.filter(clickstreamDF['column_name'] == '???').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Hack on Displaying Dataframes in Pretty Format\n",
    "\n",
    "Spark `df.show()` will print in plain text.  It can be difficult to look at, for dataframes with large number of columns.   Pandas can help here.\n",
    "\n",
    "We can easily convert Spark dataframes to Pandas dataframes.\n",
    "\n",
    "Few things to note:\n",
    "* When converting Spark --> Pandas, be mindful of size.  You don't want to accidentally convert huge Spark dataframe into Pandas.  Always use **limit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clickstreamDF.filter (\"action == 'clicked'\").limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Count the number of visits from each domain\n",
    "\n",
    "Hint : `clickstreamDF.groupBy(\"domain\").count().show()`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: \n",
    "## Hint: groupBy (\"domain\")\n",
    "clickstreamDF.groupBy(\"???\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickstreamDF.groupBy(\"???\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Spark application UI (4040+)\n",
    "\n",
    "Here you will optimizer kicking in!\n",
    "\n",
    "* Look at number of tasks (sometimes can be 100!) - but only a few tasks will actually get data.  Verify this\n",
    "* some stages will be skipped.  Because the optimizer can reuse previous results!\n",
    "* Inspect the DAG for the job.  You will see skipped stages\n",
    "\n",
    "![](../assets/images/dataframe-1.png)\n",
    "\n",
    "![](../assets/images/dataframe-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5 : Joining Dataframes\n",
    "\n",
    "Let's load another data set `domain info`  \n",
    "The data is in   `/data/click-stream/domain-info.json`  \n",
    "The data looks like this:\n",
    "\n",
    "```json\n",
    "    {\"domain\":\"amazon.com\",\"category\":\"SHOPPING\"}\n",
    "    {\"domain\":\"bbc.co.uk\",\"category\":\"NEWS\"}\n",
    "    {\"domain\":\"facebook.com\",\"category\":\"SOCIAL\"}\n",
    "    ...\n",
    "```\n",
    "\n",
    "**==> Load the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "domainsDF = spark.read.json(\"../data/click-stream/domain-info.json\")\n",
    "print(domainsDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO display domains data\n",
    "## Hint : show()\n",
    "domainsDF.???()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==> Join both dataframes**\n",
    "\n",
    "sample output\n",
    "```\n",
    "    +-------+-----------+----+-----------------+----+----------+-------------+------+-----------+-----------------+\n",
    "    | action|   campaign|cost|           domain|  ip|   session|    timestamp|  user|   category|           domain|\n",
    "    +-------+-----------+----+-----------------+----+----------+-------------+------+-----------+-----------------+\n",
    "    |clicked|campaign_19| 118|      youtube.com|ip_4|session_36|1420070400000|user_9|      VIDEO|      youtube.com|\n",
    "    |blocked| campaign_2|   7|      youtube.com|ip_2|session_93|1420070412960|user_1|      VIDEO|      youtube.com|\n",
    "    |blocked|campaign_17|  20|       amazon.com|ip_4|session_13|1420070406048|user_1|   SHOPPING|       amazon.com|\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "joined = clickstreamDF.join(domainsDF,  clickstreamDF[\"domain\"] == domainsDF[\"domain\"])\n",
    "    \n",
    "#see the results\n",
    "joined.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==> Note some rows are missing.  Which ones?  Why?**\n",
    "\n",
    "### Inspect Optimizations!\n",
    "\n",
    "open SQL tab and select the query and inspect the DAG.\n",
    "\n",
    "You will see optimizer doing some work for us already.\n",
    "\n",
    "* It is filtering on `domain != null` .  Why is that?\n",
    "* Also notice it is joing `broadcast` join for us\n",
    "\n",
    "![](../assets/images/dataframe-3.png)\n",
    "\n",
    "![](../assets/images/dataframe-4.png)\n",
    "\n",
    "![](../assets/images/dataframe-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-6: Do an OUTTER JOIN\n",
    "\n",
    "Inspect the output, might look like this\n",
    "\n",
    "**==> Can you explain the null values?**\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "    +-------+-----------+----+-----------------+----+----------+-------------+------+-----------+-----------------+\n",
    "    | action|   campaign|cost|           domain|  ip|   session|    timestamp|  user|   category|           domain|\n",
    "    +-------+-----------+----+-----------------+----+----------+-------------+------+-----------+-----------------+\n",
    "    |blocked| campaign_9| 139|          cnn.com|ip_8|session_13|1420070404320|user_7|       null|             null|\n",
    "    |   null|       null|null|             null|null|      null|         null|  null|     SOCIAL|      twitter.com|\n",
    "    |clicked| campaign_6|  15|comedycentral.com|ip_9|session_49|1420070403456|user_4|       null|             null|\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joinedOuter = clickstreamDF.join(domainsDF,  clickstreamDF[\"domain\"] == domainsDF[\"domain\"], \"outer\")\n",
    "joinedOuter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Understanding Query Execution\n",
    "\n",
    "We will use **explain** keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickstreamDF.filter(\"cost > 100\").explain(extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.explain(extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedOuter.explain(extended=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice the optimizations!\n",
    "\n",
    "There are few optimizations here\n",
    "\n",
    "* broadcast join\n",
    "* filtering on `domain != null`\n",
    "* pushed down predicates  `domain != null`\n",
    "\n",
    "![](../assets/images/dataframe-6-explain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
