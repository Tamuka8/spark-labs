<link rel='stylesheet' href='../assets/css/main.css'/>

[<< back to main index](../README.md)

Lab 4.4 : Caching 2 SQL
=================


### Overview
Understand Spark SQL Caching

### Depends On
None

### Run time
20-30 mins


## Step 1: Start Spark Shell

```bash
    $   ~/spark/bin/spark-shell
```

## Step 2: Read JSON data

```scala

val formatter = java.text.NumberFormat.getIntegerInstance

val t1 = System.currentTimeMillis()
val clickstreamDF = spark.read.json("/data/click-stream/json")
val t2 = System.currentTimeMillis()
println ("Read JSON in %s ms ".format( formatter.format(t2-t1)))

clickstreamDF.createOrReplaceTempView("clickstream")
println ("registered temp table clickstream")
spark.catalog.listTables().show()
```

## Step 3 : Query without Cache

```scala
val formatter = java.text.NumberFormat.getIntegerInstance

spark.catalog.clearCache()

val sql=""" select domain, count(*) as total from clickstream
group by domain
order by total
desc limit 10
"""

val t1 = System.currentTimeMillis()
val top10_domains = spark.sql(sql)
top10_domains.show()
val t2 = System.currentTimeMillis()
println ("Query without caching in %s ms ".format( formatter.format(t2-t1)))

```

## Step 4 : Explain Query

```scala
top10_domains.explain()

//top10_domains.explain(extended=True)
```

## Step 5 : Cache

There are 3 ways to cache
1. `dataframe.cache()`  : non blocking
2. `spark.sql("cache table TABLE_NAME")` : blocking
3. `spark.catalog.cacheTable('tableName')` : non blocking

Try all these options and see the performance implications.

```scala

spark.catalog.clearCache() // clear all tables
// spark.catalog.uncacheTable("clickstream")  # clear just one table

println ("is 'clickstream' cached : " + spark.catalog.isCached("clickstream"))

val t1 = System.currentTimeMillis()
// we have different ways to cache,
// uncomment one of the following
//spark.sql("cache table clickstream");  // 1
//clickstreamDF.cache()  // 2
spark.catalog.cacheTable("clickstream") // 3
val t2 = System.currentTimeMillis()
println ("Caching done in %s ms ".format( formatter.format(t2-t1)))
println ("is 'clickstream' cached : " + spark.catalog.isCached("clickstream"))

```

## Step 6 : Query after caching

```scala
val formatter = java.text.NumberFormat.getIntegerInstance

spark.catalog.clearCache()

val sql=""" select domain, count(*) as total from clickstream
group by domain
order by total
desc limit 10
"""

val t1 = System.currentTimeMillis()
val top10_domains = spark.sql(sql)
top10_domains.show()
val t2 = System.currentTimeMillis()
println ("Query after caching in %s ms ".format( formatter.format(t2-t1)))

```

## Step 7 : Explain Query

```scala
top10_domains.explain()

//top10_domains.explain(extended=True)
```

## Step 8 : Clear Cache
Try the following ways to clear cache

1. `spark.sql ("CLEAR CACHE")`  - removes all cache
2. `spark.sql ("CLEAR CACHE tableName")` - removes one table
3. `spark.catalog.unCacheTable('tableName')` - removes one cached table
4. `spark.catalog.clearCache()` - clear all caches
5. `dataframe.unPersist()`

```scala
spark.sql("clear cache")
// spark.catalog.clearCacheTable()
// df.unPersist()

```
