{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup your local laptop for the labs\n",
    "\n",
    "This guide will walk you through how to setup a local setup to run the labs.\n",
    "\n",
    "There are two options\n",
    "- option A (recommended) : Running our training docker image on your computer\n",
    "- option B : setup your own computer \n",
    "\n",
    "## Option A : Run training Docker \n",
    "This is the same environmnet you used for training.\n",
    "\n",
    "Here is the [docker repository](https://hub.docker.com/r/elephantscale/es-training)\n",
    "\n",
    "Follow the instructions in the above page.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Option B : Setting up your own machine\n",
    "\n",
    "### Operating System\n",
    "Setup is easier if you have either **MacOS or Linux**.   \n",
    "If you are on Windows, download the [docker image](https://hub.docker.com/repository/docker/elephantscale/es-training) and do the setup in the sandbox.\n",
    "\n",
    "## Software Needed\n",
    "- Java version 11 or later\n",
    "- Anaconda Python version 3.x\n",
    "- A few more python packages\n",
    "- Spark version 3.0 or latest\n",
    "- our data files\n",
    "\n",
    "\n",
    "### B1: Java 11\n",
    "Download and install JDK (not JRE) v11 or later from [here](https://www.oracle.com/java/technologies/javase-jdk11-downloads.html).  \n",
    "Verify you have the correct version by doing \n",
    "```\n",
    "    java -version\n",
    "```\n",
    "\n",
    "### B2: Anaconda Python\n",
    "\n",
    "Download and install Anaconda Python version 3.x from [here](https://www.anaconda.com/download/).\n",
    "\n",
    "### B3: Create a separate conda environment\n",
    "\n",
    "It is highly recommended to have a unique Conda environment, so you can have clean environments and don't run into any conflicts\n",
    "\n",
    "```bash\n",
    "# create an env called 'pyspark' with python version 3.8\n",
    "$   conda create -n pyspark python=3.8\n",
    "$   conda env list\n",
    "\n",
    "$   conda activate pyspark\n",
    "## activate pyspark env, all subsequent installs will be in this environment\n",
    "```\n",
    "\n",
    "\n",
    "### B4: Install following add-on packages\n",
    "Open a **new** terminal and run the following command\n",
    "\n",
    "```bash\n",
    "$   conda install numpy  pandas  matplotlib  seaborn  jupyter  jupyterlab\n",
    "$   conda install -c conda-forge findspark\n",
    "```\n",
    "\n",
    "Note: you can remove the environment like this\n",
    "\n",
    "```bash\n",
    "# $  conda deactivate\n",
    "# $  conda remove --name pyspark --all\n",
    "```\n",
    "\n",
    "### B5: Download Spark\n",
    "- Download latest Spark from [here](https://spark.apache.org/downloads.html)\n",
    "- Unzip the downloaded zip file\n",
    "- where Spark is unzipped is the SPARK_HOME  (in our case  `~/spark`)\n",
    "\n",
    "(Labs are tested with version 3.0 of Spark)\n",
    "\n",
    "```bash\n",
    "$   cd    # go to home directory\n",
    "$   rm -rf  spark   # cleanup existing spark installation (if any)\n",
    "\n",
    "## download\n",
    "$   wget https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
    "# alternative download location\n",
    "# $   wget  https://elephantscale-public.s3.amazonaws.com/downloads/spark-3.2.1-bin-hadoop3.2.tgz\n",
    "\n",
    "## unpack\n",
    "$   tar xvf spark-3.2.1-bin-hadoop3.2.tgz\n",
    "$   mv  spark-3.2.1-bin-hadoop3.2    spark\n",
    "```\n",
    "\n",
    "### B6: Download data files\n",
    "\n",
    "- download our data files from [here](https://s3.amazonaws.com/elephantscale-public/data/data.zip)\n",
    "\n",
    "```bash\n",
    "$   wget 'https://s3.amazonaws.com/elephantscale-public/data/data.zip'\n",
    "```\n",
    "\n",
    "- unzip this bundle in the top level project dir, so the structure looks like this\n",
    "\n",
    "```text\n",
    "    spark-labs\n",
    "        +--- README.ipynb\n",
    "        +--- data\n",
    "               +--- house-sales\n",
    "               +--- uber\n",
    "               +--- etc\n",
    "```\n",
    "\n",
    "### B7: Download labs / solutions\n",
    "Unzip them anywhere\n",
    "\n",
    "### B8: Edit  `run-jupyter.sh`\n",
    "This file is located in the labs directory. \n",
    "Edit this file to match your environment.\n",
    "\n",
    "```bash\n",
    "# TODO : Edit the following lines   \n",
    "export PATH=$HOME/anaconda3/bin:$PATH   \n",
    "export SPARK_HOME=$HOME/spark   \n",
    "jupyter lab   \n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### B9: Run the labs\n",
    "```bash\n",
    "$   ./run-jupyter.sh\n",
    "```\n",
    "\n",
    "### B10: Open and run `testing123.ipynb` file \n",
    "This file is under `0-testing` directory.   \n",
    "This file will check your setup.  \n",
    "If there are no errors here, then you are good to go\n",
    "\n",
    "### B11: Open `README.ipynb`\n",
    "And practice!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
