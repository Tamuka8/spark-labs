<p><link rel='stylesheet' href='../assets/css/main.css'/></p>
<h1 id="lab-2.2h-spark-shell-on-hadoop">Lab 2.2H: Spark Shell On Hadoop</h1>
<h3 id="overview">Overview</h3>
<p>Get familiar with Spark shell<br />
- <a href="2.2-shell-scala.html">Standalone version</a> - <a href="2.2H-spark-shell-hadoop.html">Hadoop version</a></p>
<h3 id="run-time">Run time</h3>
<p>approx. 20-30 minutes</p>
<h3 id="notes">Notes</h3>
<h2 id="step-1-login-to-hadoop-node">Step 1 : Login to Hadoop Node</h2>
<p>Follow instructions for your environment.</p>
<h2 id="step-2-start-spark-shell">Step 2 : Start Spark shell</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb1-1" data-line-number="1">    $    <span class="ex">spark-shell</span></a></code></pre></div>
<h3 id="controlling-the-ui-options">Controlling the UI options</h3>
<p>Spark Shell by default publishes a UI on port number 4040.<br />
How ever when multiple apps are running, and port 4040 already taken, Spark Shell will try to find an open port (4041, 4042 ..etc)</p>
<p>Specifying a custom port</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb2-1" data-line-number="1">    $   <span class="ex">spark-shell</span>  --conf spark.ui.port=4060</a></code></pre></div>
<p>Turn off UI altogether</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb3-1" data-line-number="1">    $   <span class="ex">spark-shell</span>  --conf spark.ui.enabled=false</a></code></pre></div>
<h2 id="step-3-set-the-log-level-to-warn">Step 3 : Set the log level to WARN</h2>
<p>Type this in Spark Shell</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode scala"><code class="sourceCode scala"><a class="sourceLine" id="cb4-1" data-line-number="1">    sc.<span class="fu">setLogLevel</span>(<span class="st">&quot;WARN&quot;</span>)</a></code></pre></div>
<h2 id="step-4-inspect-the-shell-ui">Step 4 : Inspect the Shell UI</h2>
<p>Look at the console log to identify the Spark Shell UI port.</p>
<pre class="console"><code>INFO Utils: Successfully started service &#39;SparkUI&#39; on port 4042.</code></pre>
<p>(In the above example port number of 4042).</p>
<p>Access Spark Shell UI as http://hadoop_node_ip_address:port_number</p>
<p>(Instructor will provide more details)</p>
<h1 id="section"></h1>
<p><img src="../assets/images/2a.png" style="border: 5px solid grey ; max-width:100%;" /></p>
<p><strong>==&gt; Explore stage, storage, environment and executor tabs</strong></p>
<p><strong>==&gt; Take note of ‘Event Timeline’, we will use this for monitoring our jobs later</strong></p>
<h2 id="step-5-spark-context">STEP 5: Spark context</h2>
<p>Within Spark shell, variable <code>sc</code> is the SparkContext.<br />
Type <code>sc</code> in scala prompt and see what happens.<br />
Your output might look like this…</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode scala"><code class="sourceCode scala"><a class="sourceLine" id="cb6-1" data-line-number="1">    scala&gt; sc</a>
<a class="sourceLine" id="cb6-2" data-line-number="2">    res0: org.<span class="fu">apache</span>.<span class="fu">spark</span>.<span class="fu">SparkContext</span> = org.<span class="fu">apache</span>.<span class="fu">spark</span>.<span class="fu">SparkContext</span>@5019fb90</a></code></pre></div>
<p>To see all methods in sc variable, type <code>sc.</code> (don’t forget the DOT) and type <code>TAB</code>. This will show all the available methods on <code>sc</code> variable.</p>
<p>Try the following:</p>
<p><strong>==&gt; Print the name of application name</strong> <code>sc.appName</code></p>
<p><strong>==&gt; Find the ‘Spark master’ for the shell</strong> <code>sc.master</code></p>
<h2 id="step-6-load-a-local-file">Step 6 : Load a local file</h2>
<p>Let’s load <code>/etc/hosts</code> file in Spark Shell.<br />
Issue the following commands in Spark-shell</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode scala"><code class="sourceCode scala"><a class="sourceLine" id="cb7-1" data-line-number="1">scala&gt;</a>
<a class="sourceLine" id="cb7-2" data-line-number="2">        <span class="kw">val</span> f = sc.<span class="fu">textFile</span>(<span class="st">&quot;file:///etc/hosts&quot;</span>)</a></code></pre></div>
<h4 id="answer-the-following-questions">answer the following questions:</h4>
<p><strong>==&gt; What is the ‘type’ of f ?</strong><br />
hint : type <code>f</code> on the console</p>
<p><strong>==&gt; Inspect Spark Shell UI; Do you see any processing done? Why (not)?</strong></p>
<p><strong>==&gt; Print the first line / record from RDD</strong></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode scala"><code class="sourceCode scala"><a class="sourceLine" id="cb8-1" data-line-number="1">    f.<span class="fu">first</span></a></code></pre></div>
<p><strong>==&gt; Again, inspect Spark Shell UI; do you see any processing done? Why (not)?</strong></p>
<p><strong>==&gt; Print first 3 lines of RDD</strong><br />
hint : <code>f.take(???)</code> (provide the correct argument to take function)</p>
<p><strong>==&gt; Again, inspect Spark Shell UI on port 4040, do you see any processing done? Why (not)?</strong></p>
<p><strong>==&gt; Print all the content from the file</strong></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode scala"><code class="sourceCode scala"><a class="sourceLine" id="cb9-1" data-line-number="1">    f.<span class="fu">collect</span>()</a></code></pre></div>
<p><strong>==&gt; How many lines are in the file?</strong></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode scala"><code class="sourceCode scala"><a class="sourceLine" id="cb10-1" data-line-number="1">    f.<span class="fu">count</span></a></code></pre></div>
<p><strong>==&gt; Inspect the ‘Jobs’ section in Shell UI (in browser)</strong><br />
Also inspect the event time line</p>
<p><img src="../assets/images/2b.png" style="border: 5px solid grey; max-width:100%;" /></p>
<p><strong>==&gt; Inspect the ‘Executor’ section in Shell UI (in browser)</strong></p>
<p><img src="../assets/images/2c.png" style="border: 5px solid grey; max-width:100%;" /></p>
<h2 id="step-7-load-a-hdfs-file">Step 7 : Load a HDFS file</h2>
<p>Let’s load a sample data from `/data/text/twinkle/’.<br />
Try the following in Spark-shell</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode scala"><code class="sourceCode scala"><a class="sourceLine" id="cb11-1" data-line-number="1">scala&gt;</a>
<a class="sourceLine" id="cb11-2" data-line-number="2">    <span class="kw">val</span> a = sc.<span class="fu">textFile</span>(<span class="st">&quot;/data/text/twinkle/sample.txt&quot;</span>)</a>
<a class="sourceLine" id="cb11-3" data-line-number="3"></a>
<a class="sourceLine" id="cb11-4" data-line-number="4">    <span class="co">// count the lines</span></a>
<a class="sourceLine" id="cb11-5" data-line-number="5">    a.<span class="fu">count</span></a>
<a class="sourceLine" id="cb11-6" data-line-number="6"></a>
<a class="sourceLine" id="cb11-7" data-line-number="7">    <span class="co">// print the lines</span></a>
<a class="sourceLine" id="cb11-8" data-line-number="8">    a.<span class="fu">collect</span></a>
<a class="sourceLine" id="cb11-9" data-line-number="9">    a.<span class="fu">foreach</span>(println)</a></code></pre></div>
<h2 id="step-8-use-spark-session-only-in-v2-and-later">Step 8 : Use Spark Session (Only in V2 and later)</h2>
<p>Try to load file using Spark Session</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode scala"><code class="sourceCode scala"><a class="sourceLine" id="cb12-1" data-line-number="1">scala&gt;</a>
<a class="sourceLine" id="cb12-2" data-line-number="2"></a>
<a class="sourceLine" id="cb12-3" data-line-number="3">    <span class="kw">val</span> f = spark.<span class="fu">read</span>.<span class="fu">textFile</span>(<span class="st">&quot;/data/text/twinkle/sample.txt&quot;</span>)</a>
<a class="sourceLine" id="cb12-4" data-line-number="4">    <span class="co">// Note the type of f is Dataset not RDD</span></a>
<a class="sourceLine" id="cb12-5" data-line-number="5">    <span class="co">// f: org.apache.spark.sql.Dataset[String] = [value: string]</span></a>
<a class="sourceLine" id="cb12-6" data-line-number="6"></a>
<a class="sourceLine" id="cb12-7" data-line-number="7">    f.<span class="fu">count</span></a>
<a class="sourceLine" id="cb12-8" data-line-number="8"></a>
<a class="sourceLine" id="cb12-9" data-line-number="9">    f.<span class="fu">collect</span></a>
<a class="sourceLine" id="cb12-10" data-line-number="10"></a>
<a class="sourceLine" id="cb12-11" data-line-number="11">    f.<span class="fu">foreach</span>(println)</a></code></pre></div>
<p>We can also get <code>SparkContext</code> from <code>SparkSession</code></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode scala"><code class="sourceCode scala"><a class="sourceLine" id="cb13-1" data-line-number="1">scala&gt;</a>
<a class="sourceLine" id="cb13-2" data-line-number="2">    spark.<span class="fu">sparkContext</span></a>
<a class="sourceLine" id="cb13-3" data-line-number="3">    <span class="co">// org.apache.spark.SparkContext = org.apache.spark.SparkContext@69c6e5</span></a>
<a class="sourceLine" id="cb13-4" data-line-number="4"></a>
<a class="sourceLine" id="cb13-5" data-line-number="5">    sc</a>
<a class="sourceLine" id="cb13-6" data-line-number="6">    <span class="co">//  org.apache.spark.SparkContext = org.apache.spark.SparkContext@69c6e5</span></a></code></pre></div>
<p><strong>==&gt; Quit spark-shell session <code>Control + D</code></strong></p>
<h2 id="step-9-connecting-spark-shell-to-yarn">STEP 9: Connecting Spark Shell to YARN</h2>
<p><strong>==&gt; Quit spark-shell session, if you haven’t done so yet.. <code>Control + D</code></strong></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb14-1" data-line-number="1">    $ <span class="ex">spark-shell</span>  --master yarn  --name <span class="st">&#39;MY_NAME spark shell&#39;</span></a></code></pre></div>
<p>Once the shell starts, check the ‘Resource Manager UI’ on your Hadoop system. Do you see the spark shell connected?</p>
<p>Try the following while the Spark shell is connected to YARN.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode scala"><code class="sourceCode scala"><a class="sourceLine" id="cb15-1" data-line-number="1">scala&gt;</a>
<a class="sourceLine" id="cb15-2" data-line-number="2"></a>
<a class="sourceLine" id="cb15-3" data-line-number="3">    <span class="kw">val</span> f = spark.<span class="fu">read</span>.<span class="fu">textFile</span>(<span class="st">&quot;/data/text/twinkle/sample.txt&quot;</span>)</a>
<a class="sourceLine" id="cb15-4" data-line-number="4">    <span class="co">// Note the type of f is Dataset not RDD</span></a>
<a class="sourceLine" id="cb15-5" data-line-number="5">    <span class="co">// f: org.apache.spark.sql.Dataset[String] = [value: string]</span></a>
<a class="sourceLine" id="cb15-6" data-line-number="6"></a>
<a class="sourceLine" id="cb15-7" data-line-number="7">    f.<span class="fu">count</span></a>
<a class="sourceLine" id="cb15-8" data-line-number="8"></a>
<a class="sourceLine" id="cb15-9" data-line-number="9">    f.<span class="fu">collect</span></a>
<a class="sourceLine" id="cb15-10" data-line-number="10"></a>
<a class="sourceLine" id="cb15-11" data-line-number="11">    f.<span class="fu">foreach</span>(println)</a></code></pre></div>
<h2 id="tip-dealing-with-logs">Tip : Dealing With Logs</h2>
<p>Spark Shell by default prints logs at warning (WARN) level. If you want to change the logging level, do this at Spark shell</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode scala"><code class="sourceCode scala"><a class="sourceLine" id="cb16-1" data-line-number="1">    sc.<span class="fu">setLogLevel</span>(<span class="st">&quot;INFO&quot;</span>)</a></code></pre></div>
<p>If you don’t want to see any logs, you can start Spark shell as follows. All the logs will be sent to ‘logs’ file.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode bash"><code class="sourceCode bash"><a class="sourceLine" id="cb17-1" data-line-number="1">    $    <span class="ex">spark-shell</span>  <span class="op">2&gt;</span> logs</a></code></pre></div>
<h2 id="tips-and-tricks-to-run-linux-command-without-leaving-the-shell">TIPS and TRICKS: To run Linux command without leaving the shell</h2>
<div class="sourceCode" id="cb18"><pre class="sourceCode scala"><code class="sourceCode scala"><a class="sourceLine" id="cb18-1" data-line-number="1">    <span class="kw">import</span> sys.<span class="fu">process</span>._</a>
<a class="sourceLine" id="cb18-2" data-line-number="2">    <span class="kw">val</span> result = <span class="st">&quot;ls -al&quot;</span>!</a></code></pre></div>
