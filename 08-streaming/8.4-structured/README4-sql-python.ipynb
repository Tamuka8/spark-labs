{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - Structured Streaming 4 - SQL\n",
    "\n",
    "\n",
    "### Overview\n",
    "\n",
    "Use Spark SQL in structured streaming\n",
    "\n",
    "### Depends On\n",
    "\n",
    "clickstream lab\n",
    "\n",
    "### Run time\n",
    "\n",
    "20-30 mins\n",
    "\n",
    "\n",
    "## STEP 1: Go to project directory\n",
    "\n",
    "```bash\n",
    "$ cd ~/dev/spark-labs/08-streaming/8.4-structured/\n",
    "```\n",
    "\n",
    "## Step 2 : Inspect file `sql.py`\n",
    "\n",
    "Inspect file : [python/sql.py](python/sql.py) \n",
    "\n",
    "## Step 3 - Run the file\n",
    "\n",
    "```bash\n",
    "# be in project root directory\n",
    "$   cd ~/dev/spark-labs/08-streaming/8.4-structured\n",
    "\n",
    "$   rm -f input/* ;  \\\n",
    "    ~/apps/spark/bin/spark-submit --master local[2] \\\n",
    "    --driver-class-path logging/ \\\n",
    "    python/sql.py\n",
    "```\n",
    "\n",
    "## Step 4 - Supply Input\n",
    "\n",
    "The program is waiting to read files in `input/` directory.   Let's add some files.\n",
    "\n",
    "```bash\n",
    "$   cd ~/dev/spark-labs/08-streaming/8.4-structured\n",
    "$   cp   clickstream.json   input/1.json\n",
    "```\n",
    "Watch the output.\n",
    "\n",
    "It would look something like this:\n",
    "\n",
    "```console\n",
    "-------------------------------------------\n",
    "Batch: 0\n",
    "-------------------------------------------\n",
    "+-------+-----------+----+-----------------+----+----------+-------------+------+------------------+\n",
    "| action|   campaign|cost|           domain|  ip|   session|    timestamp|  user|             query|\n",
    "+-------+-----------+----+-----------------+----+----------+-------------+------+------------------+\n",
    "|clicked|campaign_19| 118|      youtube.com|ip_4|session_36|1420070400000|user_9|query1-clickstream|\n",
    "|blocked|campaign_12|   5|     facebook.com|ip_3|session_96|1420070400864|user_5|query1-clickstream|\n",
    "|clicked| campaign_3|  54|sf.craigslist.org|ip_9|session_61|1420070401728|user_8|query1-clickstream|\n",
    "| viewed|campaign_20| 133|       google.com|ip_9|session_69|1420070416416|user_7|query1-clickstream|\n",
    "+-------+-----------+----+-----------------+----+----------+-------------+------+------------------+\n",
    "\n",
    "```\n",
    "\n",
    "## Step 5: Complete TODOs\n",
    "\n",
    "Edit file : [python/sql.py](python/sql.py) \n",
    "\n",
    "Complete TODO items\n",
    "\n",
    "\n",
    "## Step 6: Run the streaming application\n",
    "\n",
    "```bash\n",
    "# be in project root directory\n",
    "$   cd ~/dev/spark-labs/08-streaming/8.4-structured\n",
    "\n",
    "$   rm -f input/* ;  \\\n",
    "    ~/apps/spark/bin/spark-submit --master local[2] \\\n",
    "    --driver-class-path logging/ \\\n",
    "    python/sql.py\n",
    "```\n",
    "\n",
    "Note : `rm -f input/*`  is used to clear the input directory\n",
    "\n",
    "Leave this terminal running (we will call it Spark terminal)\n",
    "\n",
    "## Step 7 - Provide Input\n",
    "\n",
    "Open another terminal and issue the following commands.\n",
    "\n",
    "```bash\n",
    "$   cd ~/dev/spark-labs/08-streaming/8.4-structured/\n",
    "$   cp clickstream.json input/1.json\n",
    "```\n",
    "\n",
    "In Spark terminal you should see the first batch output.\n",
    "\n",
    "And you should also see the result of SQL query.\n",
    "\n",
    "\n",
    "```console\n",
    "-------------------------------------------\n",
    "Batch: 0\n",
    "-------------------------------------------\n",
    "+-------+-----------+----+-----------------+----+----------+-------------+------+\n",
    "| action|   campaign|cost|           domain|  ip|   session|    timestamp|  user|\n",
    "+-------+-----------+----+-----------------+----+----------+-------------+------+\n",
    "|clicked|campaign_19| 118|      youtube.com|ip_4|session_36|1420070400000|user_9|\n",
    "|blocked|campaign_12|   5|     facebook.com|ip_3|session_96|1420070400864|user_5|\n",
    "|clicked| campaign_3|  54|sf.craigslist.org|ip_9|session_61|1420070401728|user_8|\n",
    "|blocked|campaign_18| 110|    wikipedia.org|ip_5|session_55|1420070402592|user_6|\n",
    "|clicked| campaign_6|  15|comedycentral.com|ip_9|session_49|1420070403456|user_4|\n",
    "|blocked| campaign_9| 139|          cnn.com|ip_8|session_13|1420070404320|user_7|\n",
    "....\n",
    "\n",
    "\n",
    "+-----------------+------+-----+\n",
    "|           domain|visits|spend|\n",
    "+-----------------+------+-----+\n",
    "|    wikipedia.org|     3|  301|\n",
    "|      youtube.com|     2|  125|\n",
    "|          cnn.com|     1|  139|\n",
    "|       sfgate.com|     1|   74|\n",
    "|   funnyordie.com|     1|  171|\n",
    "+-----------------+------+-----+\n",
    "\n",
    "```\n",
    "\n",
    "## Step 8 - Provide more input\n",
    "\n",
    "Observe the output.\n",
    "\n",
    "You will see the `visits` change\n",
    "\n",
    "\n",
    "```bash\n",
    "$   cp   clickstream.json  input/2.json\n",
    "$   cp   clickstream.json  input/3.json\n",
    "```\n",
    "\n",
    "## Step 9 : Terminate the app\n",
    "\n",
    "**=>  Hit Ctrl+C  on terminal #1 to kill Spark streaming application**\n",
    "\n",
    "\n",
    "## BONUS Step : Modify the Query\n",
    "\n",
    "Come up with another query and check the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
