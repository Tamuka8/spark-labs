{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab : Classification with MLlib\n",
    "===================================\n",
    "### OverView\n",
    "We will be running a binary classifier using a Support Vector Machine (SVM)\n",
    "\n",
    "### Depends On\n",
    "None\n",
    "\n",
    "### Run time\n",
    "30 mins\n",
    "\n",
    "\n",
    "## STEP 1: Examine the Churn Dataset\n",
    "The churn dataset is located in /data/churn/ directory.  There is already\n",
    "broken out a churntest.csv and a churntrain.csv.  Normally, we split\n",
    "up the dataset but in this case it's done for you.\n",
    "\n",
    "Note the outcome variable is simply called \"churn\".  If the customer leaves,\n",
    "churn is 1, if not, 0. The outcome variable happens to be the last variable in the dataset.\n",
    "\n",
    "The other variables are as follows:\n",
    "* 0:\"id\": Id\n",
    "* 1:\"state\": what state (2 letter abberviation)\n",
    "* 2:\"account_length\":  Length of customer account\n",
    "* 3:\"area_code\" a string containing the area code \n",
    "* 4:\"international_plan\", whether or not international plan\n",
    "* 5:\"voice_mail_plan\", whether or not voice mail plan\n",
    "* 6:\"number_vmail_messages\", an integer with the number of voice mails\n",
    "* 7:\"total_day_minutes\" an integer with total daytime minutes used\n",
    "* 8:\"total_day_calls\" an integer with the total number of daytime calls\n",
    "* 9:\"total_day_charge\": the charge for the daytime calls\n",
    "* 10:\"total_eve_minutes: total number of evening minutes used\n",
    "* 11:\"total_eve_calls\": total numbe of evening calls\n",
    "* 12:\"total_eve_charge\": total charge for evening calls\n",
    "* 13:\"total_night_minutes\": total number of night minutes used\n",
    "* 14:\"total_night_calls\": total number of nigh calls\n",
    "* 15:\"total_night_charge\": total chage for nights\n",
    "* 16:\"total_intl_minutes\": total international minutes used\n",
    "* 17:\"total_intl_calls\", total number of international calls\n",
    "* 18:\"total_intl_charge\": total charge for international calls.\n",
    "* 19:\"number_customer_service_calls\" integer number of times called customer service \n",
    "* 20:\"churn\" Outcome Variable  yes/no churn or did not churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Spark...\n",
      "Spark found in :  /home/ubuntu/spark\n",
      "Spark config:\n",
      "\t spark.app.name=TestApp\n",
      "\tspark.master=local[*]\n",
      "\texecutor.memory=2g\n",
      "\tspark.sql.warehouse.dir=/tmp/tmp5vgz50an\n",
      "\tsome_property=some_value\n",
      "Spark UI running on port 4045\n"
     ]
    }
   ],
   "source": [
    "# initialize Spark Session\n",
    "import os\n",
    "import sys\n",
    "top_dir = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "if top_dir not in sys.path:\n",
    "    sys.path.append(top_dir)\n",
    "\n",
    "from init_spark import init_spark\n",
    "spark = init_spark()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Prepare the data:\n",
    "MLLib Vectors only accepts numeric data.  This dataset has some non-numeric fields.  Note which fields are non-numeric.\n",
    "\n",
    "Create a function called get_labeled_point to parse the data. It should return\n",
    "type Labeledpoint. which should have the outcome variable churn,\n",
    "and a Vectors.dense of all the other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_point(csv_line_data):\n",
    "#     TODO: drop the non-numeric fields, convert the rest to double. \n",
    "    parts = ???\n",
    "#     TODO Return Labeledpoint:  Outcome variable, Vectors.dense(all other variables)\n",
    "    return LabeledPoint(???, ???)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse the data\n",
    "trainingData = sc.textFile(\"../../../data/churn/churntrain.csv\").map(get_labeled_point)\n",
    "testData = sc.textFile(\"../../../data/churn/churntest.csv\").map(get_labeled_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training algorithm to build the model\n",
    "model = SVMWithSGD.train(trainingData, iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the default threshold.\n",
    "model.clearThreshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Complete the TODO items to generate score and labels.\n",
    "\n",
    "Use model.predict on the test data.  Calculate the score.  Then return a tuple of score and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute raw scores on the test set. \n",
    "def get_score_and_labels(test_data):\n",
    "#     TODO : use model.predict to get the score\n",
    "    score = ???\n",
    "    return (score, test_data.label)\n",
    "\n",
    "score_and_labels = testData.map(get_score_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the values to float type\n",
    "score_and_labels_in_float = scoreAndLabels.map(lambda x : (float(x[0]),float(x[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: Note the Area under ROC\n",
    "\n",
    "We measure our model's performance by measuring the area under the ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get evaluation metrics\n",
    "metrics = BinaryClassificationMetrics(score_and_labels_in_float)\n",
    "metrics.areaUnderROC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
