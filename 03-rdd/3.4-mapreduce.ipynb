{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel='stylesheet' href='../assets/css/main.css'/>\n",
    "\n",
    "<< [back to main index](../README.md) \n",
    "\n",
    "Lab 3.4: Map Reduce\n",
    "===================\n",
    "### Overview\n",
    "Learn MapReduce in Spark step by step\n",
    "\n",
    "### Depends On \n",
    "None\n",
    "\n",
    "### Run time\n",
    "20 mins\n",
    "\n",
    "\n",
    "--------------------------\n",
    "STEP 1: Launch Spark Shell\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$   ~/spark/bin/spark-shell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> Make an RDD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "    // scala\n",
    "    val input = Array (\"hello world\", \"good bye world\", \"ok bye\")\n",
    "    val r = sc.makeRDD(input)    // this works in the same way as 'parallelize'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> Add up the words and counts**\n",
    "\n",
    "------------\n",
    "STEP 2 : Map\n",
    "------------\n",
    "**=> Apply `map()` function to rdd**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val r2 = r.map(line => line.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> Print out the results by `collect()`**  \n",
    "**=> Notice the resulting RDD type**\n",
    "\n",
    "---------------\n",
    "STEP 3: flatMap\n",
    "---------------\n",
    "**=> Use `flatMap` to create another RDD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val r3 = r.flatMap( line => line.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=> Print out the results, can you explain the data type**\n",
    "\n",
    "\n",
    "----------------------\n",
    "STEP 4: Create KV pair\n",
    "----------------------\n",
    "**=> Create a key-value pair by using `flatMap` and `map`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val r4 = r.flatMap(line => line.split(\" \")).map(word => (word, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "STEP 5: reduceByKey\n",
    "-------------------\n",
    "**=> Add up the words and counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val r5 = r4.reduceByKey((a,b) => a+b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "STEP 6:  Generating data\n",
    "------------------------\n",
    "If you haven't done so yet,  generate some 'twinkle' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$   cd  ~/spark-labs/data/twinkle\n",
    "$   ./create-data-files.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will generate a bunch of data files at various sizes (1M, 10M, 100M, 500M and 1G)\n",
    "Verify the data files and their sizes by doing a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$   ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use these files as input\n",
    "\n",
    "\n",
    "------------------------\n",
    "STEP 7:  Do wordcount on larger file\n",
    "------------------------\n",
    "Load one of the larger files (100M + )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val f = sc.textFile(\"file path\")\n",
    "// do the wordcount"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
