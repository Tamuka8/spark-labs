import org.apache.spark.graphx._
import org.apache.spark.rdd.RDD
import org.apache.spark.graphx.util.GraphGenerators

val vertexArray = Array(
    // direct connections
    (1L, ("Mark Kerzner", 2757)),
    (2L, ("Sujee Maniyam", 891)),
    (3L, ("Yaakov Weintraub", 105)),
    (4L, ("Packt Publishing", 2984)),
    (5L, ("Barry Kaufman ", 500)),
    // indirect connections
    (6L, ("Ron Bodkin", 500)),
    (7L, ("Ron's friend", 500))
)
val edgeArray = Array(
    Edge(1L, 2L, 1),
    Edge(1L, 3L, 1),
    Edge(1L, 4L, 1),
    Edge(1L, 5L, 1),
    Edge(2L, 6L, 1),
    Edge(6L, 7L, 1)
)
val vertexRDD: RDD[(Long, (String, Int))] = sc.parallelize(vertexArray)
val edgeRDD: RDD[Edge[Int]] = sc.parallelize(edgeArray)
val graph: Graph[(String, Int), Int] = Graph(vertexRDD, edgeRDD)
graph.vertices.collect.foreach { case (id, (name, nConnection)) => println(s"Linkedin $name with $nConnection") }
val sourceId: VertexId = 1

val initialGraph = graph.mapVertices((id, _) => if (id == sourceId) 0.0 else Double.PositiveInfinity)

initialGraph.vertices.collect.foreach { case (id) => println(s"VertexId: $id") }

val sssp = initialGraph.pregel(Double.PositiveInfinity)(
    (id, dist, newDist) => math.min(dist, newDist), // Vertex Program
        triplet => {  // Send Message
        if (triplet.srcAttr + triplet.attr < triplet.dstAttr) {
            Iterator((triplet.dstId, triplet.srcAttr + triplet.attr))
        } else {
            Iterator.empty
        }
    },
    (a,b) => math.min(a,b) // Merge Message
)
println(sssp.vertices.collect.mkString("\n"))
